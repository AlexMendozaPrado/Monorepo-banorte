# ==========================================
# AI Provider Configuration
# ==========================================
# Options: 'openai' | 'ollama'
AI_PROVIDER=openai

# ==========================================
# OpenAI Configuration
# ==========================================
OPENAI_API_KEY=your_openai_api_key_here
DEFAULT_MODEL=gpt-4

# ==========================================
# Ollama Configuration
# ==========================================
# Base URL del servidor Ollama (default: http://localhost:11434)
OLLAMA_BASE_URL=http://localhost:11434
# Modelo a usar (ejemplos: llama3.2, qwen2.5, llama3.1, mistral, codellama)
OLLAMA_MODEL=llama3.2

# ==========================================
# Configuración Común de Análisis
# ==========================================
# Máximo de tokens a generar (opcional - Ollama default: -1, OpenAI default: 4000)
MAX_TOKENS=4000
# Temperatura de creatividad (opcional - Ollama default: 0.8, OpenAI default: 0.3)
TEMPERATURE=0.3

# ==========================================
# Application Configuration
# ==========================================
NEXT_PUBLIC_APP_NAME=Banorte Sentiment Analysis
NEXT_PUBLIC_APP_VERSION=1.0.0

# ==========================================
# File Upload Configuration
# ==========================================
MAX_FILE_SIZE=10485760  # 10MB in bytes
ALLOWED_FILE_TYPES=application/pdf
